 {
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identity Document Classification using ResNet50\n",
    "\n",
    "This notebook demonstrates how to use ResNet50 with transfer learning for identity document classification.\n",
    "\n",
    "ResNet (Residual Network) is a powerful CNN architecture that introduced skip connections to solve the vanishing gradient problem in deep networks. ResNet50 has 50 layers and was trained on the ImageNet dataset, making it capable of extracting rich features for various computer vision tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "# Add current directory to path to import local modules\n",
    "sys.path.append('.')\n",
    "\n",
    "# Import custom modules\n",
    "from dataset import load_data, IDDocumentDataset, get_transforms\n",
    "from models import create_resnet50\n",
    "from train import train_model, evaluate_model, visualize_training_history, model_summary, visualize_misclassified_samples\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Let's configure our training parameters. ResNet50 is a larger model compared to EfficientNet-B0, so we'll adjust the learning parameters accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data parameters\n",
    "DATA_DIR = '../../data/cropped_images'  # Path to dataset directory\n",
    "IMG_SIZE = 224  # Input image size for ResNet50\n",
    "VAL_SPLIT = 0.15  # Percentage of data to use for validation\n",
    "TEST_SPLIT = 0.15  # Percentage of data to use for testing\n",
    "BATCH_SIZE = 24  # Slightly smaller batch size due to model size\n",
    "NUM_WORKERS = 4  # Number of workers for data loading\n",
    "\n",
    "# Training parameters - tuned for ResNet50 transfer learning\n",
    "EPOCHS = 25  # Maximum number of epochs to train for\n",
    "LEARNING_RATE = 1e-4  # Lower learning rate for ResNet50\n",
    "WEIGHT_DECAY = 1e-4  # L2 regularization\n",
    "PATIENCE = 8  # Early stopping patience\n",
    "CHECKPOINT_DIR = Path('../../checkpoints/resnet50')  # Directory to save model checkpoints\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)  # Create checkpoint directory if it doesn't exist\n",
    "\n",
    "# Transfer learning settings\n",
    "PRETRAINED = True  # Use pretrained weights\n",
    "FREEZE_BACKBONE = True  # Freeze backbone layers except the last one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Exploration\n",
    "\n",
    "Let's load our dataset and explore it. We'll use the same data loading function as in the other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the data\n",
    "data = load_data(\n",
    "    data_dir=DATA_DIR,\n",
    "    img_size=IMG_SIZE,\n",
    "    val_split=VAL_SPLIT,\n",
    "    test_split=TEST_SPLIT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Get class names\n",
    "class_names = data['class_names']\n",
    "num_classes = data['num_classes']\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Visualization\n",
    "\n",
    "Let's visualize some random samples from our dataset to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualize_original_samples(dataset, class_names, num_images=5, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Visualize original samples from a dataset without any transformations.\n",
    "    \n",
    "    Args:\n",
    "        dataset: PyTorch dataset object\n",
    "        class_names (list): List of class names\n",
    "        num_images (int): Number of images to display\n",
    "        figsize (tuple): Figure size\n",
    "    \"\"\"\n",
    "    # Select random indices\n",
    "    indices = np.random.choice(len(dataset), num_images, replace=False)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=figsize)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        # Get image path and label directly from dataset\n",
    "        img_path = dataset.image_paths[idx]\n",
    "        label = dataset.labels[idx]\n",
    "        \n",
    "        # Load original image without transformations\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display image\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(f\"Class: {class_names[label]}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize random samples from the training set\n",
    "print(\"Random training samples:\")\n",
    "visualize_original_samples(data['train_dataset'], class_names)\n",
    "\n",
    "# Visualize one sample from each class\n",
    "print(\"\\nOne sample from each class:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    # Find indices of samples from this class\n",
    "    class_indices = [j for j, label in enumerate(data['train_dataset'].labels) if label == i]\n",
    "    if class_indices:  # Make sure we have samples of this class\n",
    "        # Select one random sample\n",
    "        idx = random.choice(class_indices)\n",
    "        \n",
    "        # Get image path and load image\n",
    "        img_path = data['train_dataset'].image_paths[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display image\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Class: {class_name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating and Configuring the ResNet50 Model\n",
    "\n",
    "Now we'll create our ResNet50 model with pretrained weights and configure it for our document classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create the ResNet50 model\n",
    "model = create_resnet50(\n",
    "    num_classes=num_classes,\n",
    "    pretrained=PRETRAINED,\n",
    "    freeze_backbone=FREEZE_BACKBONE\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "model_summary(model)\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.2%} of total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setting Up Training Components\n",
    "\n",
    "Let's set up our loss function, optimizer, and learning rate scheduler for training ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define loss function with label smoothing for better generalization\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1) \n",
    "\n",
    "# Define optimizer - AdamW with weight decay for regularization\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# For a partially frozen model like this, we'll use OneCycleLR\n",
    "# which works well for transfer learning with larger models\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=LEARNING_RATE,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=len(data['train_loader']),\n",
    "    pct_start=0.2,  # Spend 20% of time warming up\n",
    "    div_factor=10,  # LR starts at max_lr/10\n",
    "    final_div_factor=100,  # Final LR is max_lr/100\n",
    "    anneal_strategy='cos'  # Cosine annealing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training the Model\n",
    "\n",
    "Now we'll train our ResNet50 model. We're using early stopping to prevent overfitting and to save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate a unique model name with timestamp\n",
    "model_name = f\"resnet50_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "# Train the model\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    dataloaders={\n",
    "        'train': data['train_loader'],\n",
    "        'val': data['val_loader']\n",
    "    },\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=EPOCHS,\n",
    "    device=device,\n",
    "    save_dir=CHECKPOINT_DIR,\n",
    "    model_name=model_name,\n",
    "    early_stopping_patience=PATIENCE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizing Training Results\n",
    "\n",
    "Let's visualize our training history to see how the model performed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize training history\n",
    "visualize_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation\n",
    "\n",
    "Now let's evaluate our trained model on the test set to see how well it generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate the model on the test set\n",
    "test_metrics = evaluate_model(model, data['test_loader'], device, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Analyzing Misclassifications\n",
    "\n",
    "Let's look at examples that our model misclassified to understand its weaknesses and potential areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize misclassified samples\n",
    "visualize_misclassified_samples(model, data['test_loader'], class_names, device, num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Fine-tuning the Model\n",
    "\n",
    "Now, let's try fine-tuning by unfreezing more layers of the network. This is a common practice to further improve performance after initial training with frozen backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Unfreeze the last two blocks (layer3 and layer4) for fine-tuning\n",
    "for name, param in model.named_parameters():\n",
    "    if any(block in name for block in ['layer3', 'layer4', 'fc']):\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Count trainable parameters after unfreezing\n",
    "trainable_params_finetuned = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters after unfreezing: {trainable_params_finetuned:,} ({trainable_params_finetuned/total_params:.2%} of total)\")\n",
    "\n",
    "# Setup for fine-tuning with a lower learning rate\n",
    "ft_learning_rate = LEARNING_RATE / 10  # Lower learning rate for fine-tuning\n",
    "ft_epochs = 10  # Fewer epochs for fine-tuning\n",
    "\n",
    "# New optimizer and scheduler for fine-tuning\n",
    "ft_optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                         lr=ft_learning_rate, \n",
    "                         weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "ft_scheduler = CosineAnnealingLR(ft_optimizer, T_max=ft_epochs)\n",
    "\n",
    "# Fine-tune the model\n",
    "print(\"\\nFine-tuning the model with unfrozen layers...\")\n",
    "ft_model_name = f\"{model_name}_finetuned\"\n",
    "model, ft_history = train_model(\n",
    "    model=model,\n",
    "    dataloaders={\n",
    "        'train': data['train_loader'],\n",
    "        'val': data['val_loader']\n",
    "    },\n",
    "    criterion=criterion,\n",
    "    optimizer=ft_optimizer,\n",
    "    scheduler=ft_scheduler,\n",
    "    num_epochs=ft_epochs,\n",
    "    device=device,\n",
    "    save_dir=CHECKPOINT_DIR,\n",
    "    model_name=ft_model_name,\n",
    "    early_stopping_patience=3  # Shorter patience for fine-tuning\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Evaluating the Fine-tuned Model\n",
    "\n",
    "Let's see if fine-tuning improved the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize fine-tuning history\n",
    "visualize_training_history(ft_history)\n",
    "\n",
    "# Evaluate the fine-tuned model on the test set\n",
    "ft_test_metrics = evaluate_model(model, data['test_loader'], device, class_names)\n",
    "\n",
    "# Compare metrics before and after fine-tuning\n",
    "print(\"\\nComparison of metrics before and after fine-tuning:\")\n",
    "print(f\"Initial model - Accuracy: {test_metrics['accuracy']:.4f}, F1 Score: {test_metrics['f1']:.4f}\")\n",
    "print(f\"Fine-tuned model - Accuracy: {ft_test_metrics['accuracy']:.4f}, F1 Score: {ft_test_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Saving the Fine-tuned Model\n",
    "\n",
    "Let's save our fine-tuned model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the fine-tuned model\n",
    "save_path = os.path.join(CHECKPOINT_DIR, f\"{ft_model_name}_final.pth\")\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'class_names': class_names,\n",
    "    'num_classes': num_classes,\n",
    "    'img_size': IMG_SIZE,\n",
    "    'metrics': ft_test_metrics,\n",
    "    'model_type': 'resnet50'\n",
    "}, save_path)\n",
    "print(f\"Fine-tuned model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Inference on Single Image\n",
    "\n",
    "Let's use our fine-tuned model to classify individual images and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def predict_single_image(model, image_path, transform, class_names, device):\n",
    "    \"\"\"\n",
    "    Predict class for a single image and visualize the result.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        image_path: Path to the image file\n",
    "        transform: Transformation pipeline for inference\n",
    "        class_names: List of class names\n",
    "        device: Device to run inference on\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display original image\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Apply transformations\n",
    "    transformed = transform(image=image)\n",
    "    image_tensor = transformed['image']\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)  # Add batch dimension\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        values, indices = torch.topk(probabilities, 3)  # Get top 3 predictions\n",
    "    \n",
    "    # Display prediction results\n",
    "    values = values.squeeze().cpu().numpy() * 100  # Convert to percentage\n",
    "    indices = indices.squeeze().cpu().numpy()\n",
    "    \n",
    "    print(\"Top 3 predictions:\")\n",
    "    for i in range(min(3, len(class_names))):\n",
    "        print(f\"{class_names[indices[i]]}: {values[i]:.2f}%\")\n",
    "    \n",
    "    # Create a horizontal bar chart for visualization\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.barh(y=[class_names[idx] for idx in indices[:3]], width=values[:3])\n",
    "    plt.xlabel('Confidence (%)')\n",
    "    plt.title('Top 3 Predictions')\n",
    "    plt.xlim(0, 100)\n",
    "    plt.gca().invert_yaxis()  # Highest confidence at the top\n",
    "    plt.show()\n",
    "\n",
    "# Get test images for inference\n",
    "test_dataset = data['test_dataset']\n",
    "test_indices = np.random.choice(len(test_dataset), 3, replace=False)\n",
    "\n",
    "# Use validation/test transform for inference (no augmentation)\n",
    "inference_transform = get_transforms(img_size=IMG_SIZE)['test']\n",
    "\n",
    "# Run inference on multiple test images\n",
    "for idx in test_indices:\n",
    "    test_image_path = test_dataset.image_paths[idx]\n",
    "    test_label = test_dataset.labels[idx]\n",
    "    print(f\"\\nTrue class: {class_names[test_label]}\")\n",
    "    predict_single_image(model, test_image_path, inference_transform, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Model Inference Performance\n",
    "\n",
    "Let's measure the inference time of our ResNet50 model to understand its performance in a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "def measure_inference_time(model, dataloader, device, num_runs=100):\n",
    "    \"\"\"\n",
    "    Measure the average inference time per image.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        dataloader: PyTorch dataloader containing test data\n",
    "        device: Device to run inference on\n",
    "        num_runs: Number of inference runs to average over\n",
    "    \n",
    "    Returns:\n",
    "        float: Average inference time per image in milliseconds\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Get a single batch for testing\n",
    "    inputs, _ = next(iter(dataloader))\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    # Warm-up runs\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = model(inputs[0:1])\n",
    "    \n",
    "    # Measure inference time\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            _ = model(inputs[0:1])  # Run inference on a single image\n",
    "    \n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate average time in milliseconds\n",
    "    avg_time = (end_time - start_time) * 1000 / num_runs\n",
    "    \n",
    "    return avg_time\n",
    "\n",
    "# Measure inference time\n",
    "avg_inference_time = measure_inference_time(model, data['test_loader'], device)\n",
    "print(f\"Average inference time per image: {avg_inference_time:.2f} ms\")\n",
    "print(f\"Frames per second: {1000 / avg_inference_time:.2f} FPS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Conclusion\n",
    "\n",
    "In this notebook, we've walked through the process of using ResNet50 with transfer learning for identity document classification:\n",
    "\n",
    "1. We set up our environment and loaded our dataset\n",
    "2. We explored and visualized the dataset\n",
    "3. We created a ResNet50 model with pretrained weights\n",
    "4. We configured the model for our classification task, initially freezing most of the backbone\n",
    "5. We trained the model using OneCycleLR scheduling and label smoothing\n",
    "6. We evaluated the model and analyzed its performance\n",
    "7. We fine-tuned the model by unfreezing more layers and training with a lower learning rate\n",
    "8. We compared performance before and after fine-tuning\n",
    "9. We performed inference on test images\n",
    "10. We measured inference performance to understand real-world usage characteristics\n",
    "\n",
    "ResNet50 is a powerful architecture for this document classification task because:\n",
    "1. Its residual connections allow for deeper networks without vanishing gradients\n",
    "2. The pretrained weights provide a strong starting point for transfer learning\n",
    "3. It has a good balance of model capacity and inference speed\n",
    "\n",
    "For further improvements, you could:\n",
    "1. Try different training strategies (e.g., gradual unfreezing)\n",
    "2. Experiment with different learning rates for different layers\n",
    "3. Implement more advanced data augmentation techniques specific to document images\n",
    "4. Ensemble this model with other architectures, like EfficientNet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}